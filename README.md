## Overview  

This is a demo social-media platform that uses AI to assess toxicity in posts and comments. Users can create accounts, submit posts and comments, and receive a toxicity score generated by an ONNX model. The core features include:  

- User registration and authentication  
- Creating posts and comments  
- Real-time toxicity scoring using a quantised ONNX model  

## Prerequisites  

Ensure you have the following installed:  
- **Python 3.11+**  
- **pip** to install Python dependencies  
- **Node.js 22+** and **pnpm** for the Next.js frontend/backend  
- A UNIX-style shell (macOS, Linux or WSL)  


## Setup & Installation

1. **Clone repository**

```bash
git clone https://github.com/newbee1905/aix.git
cd aix
```

2. **Python Environment**

```bash
cd scripts
python -m venv venv
source venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
```

3. **Install Node.js dependencies**

```bash
pnpm i
```

## Extracting & Quantising the Toxicity Model


```bash
cd scripts
source venv/bin/activate

python export_and_quantize.py                

cp -r ../public/models ../models
```

If you want to change the model, please use the `username/model-name` format on hugging face, and change the variable `TOX_MODEL_ID`.

Please also change the variable `TOX_MODEL_ID` inside `src/lib/onnx.ts`.

## Environment Variables

Please create a `.env` with your database information. You can configure the JWT exiration and Refresh Token Expiration to your liking.

```
POSTGRES_PRISMA_URL="postgres://username@localhost:5432/database_name"
JWT_SECRET=your-secret
JWT_EXPIRES_IN=86400 # 1 day 
REFRESH_EXPIRES_IN=2592000 # 30 days
REFRESH_ROTATE_BEFORE=1296000 # 15 days
```

## Running the Application

```
pnpm dev
```
